{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_document_to_chunks(row, field_name, chunk_len):\n",
    "    text = row[field_name]\n",
    "    if(text!='[]'):\n",
    "        label = row['label']\n",
    "        sentences = sent_tokenize(text)\n",
    "        output = []\n",
    "        for i in range(0,len(sentences), chunk_len):\n",
    "            if(i+chunk_len < len(sentences)):\n",
    "                chunk = ''.join(sentences[i:i+chunk_len])\n",
    "            else:\n",
    "                chunk = ''.join(sentences[i:len(sentences)])\n",
    "            output.append((chunk,label))\n",
    "        return output\n",
    "def prepare_data_set(data_set):\n",
    "    chunked_text_labels = data_set.apply(split_document_to_chunks, args=('filteredtext_aapl', 1), axis=1)\n",
    "    X=[]\n",
    "    y=[]\n",
    "    for chunks in chunked_text_labels:\n",
    "        if(chunks is not None):\n",
    "            for chunk in chunks:\n",
    "                X.append(chunk[0])\n",
    "                y.append(chunk[1])\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = pd.read_csv('../Data/final_dataset_joined_aapl240_onlyMentions.csv')\n",
    "train_df = data_set[data_set.stock_time <= \"2018-12-01 00:00:00\"]\n",
    "test_df = data_set[data_set.stock_time > \"2018-12-01 00:00:00\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67276, 67276)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,y_train = prepare_data_set(train_df)\n",
    "len(X_train),len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [nape summit week will also feature the annual...\n",
       "1        [from apples hugely anticipated iphone x to sa...\n",
       "2        [they are not just the largest browser, but th...\n",
       "3        [the humanitarian crisis in the drc has placed...\n",
       "4        [cramer prefers finisar (nasdaq: fnsr ) after ...\n",
       "                               ...                        \n",
       "62795    [and the outperformance in health care, displa...\n",
       "62796    [and the outperformance in health care, displa...\n",
       "62797    [microsoft's market value overtakes apple's to...\n",
       "62798    [microsoft's market value overtakes apple's to...\n",
       "62799    [microsoft's market value overtakes apple's to...\n",
       "Name: filteredtext_aapl, Length: 62800, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.filteredtext_aapl.apply(lambda x: (sent_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian',\n",
    "             'comp.graphics', 'sci.med']\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "train_b = fetch_20newsgroups(subset='train',\n",
    "   categories=categories, shuffle=True, random_state=42)\n",
    "test_b = fetch_20newsgroups(subset='test',\n",
    "   categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_b.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 3, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_b.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
